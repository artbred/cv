{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install pandas python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "known_utm_combinations = [\n",
    "    [\"linkedin\", \"apply_directly_linkedin\"],  # Apply for job directy through linkedin\n",
    "    [\"linkedin\", \"linkedin_profile_page\"],\n",
    "    [\"linkedin\", \"msg_linkedin\"], # Find someone in a company that is hiring\n",
    "\n",
    "    [\"email\", \"msg_email\"], # Message someone directly\n",
    "\n",
    "    [\"github\", \"cv_repository_readme\"], #Link placed in readme.md\n",
    "\n",
    "    [\"pdf\", \"backend-developer-v1\"], # Placed in pdf\n",
    "    [\"pdf\", \"product-manager-v1\"]\n",
    "]\n",
    "\n",
    "known_utm_combinations_df = pd.DataFrame(known_utm_combinations, columns=['utm_source', 'utm_campaign'])\n",
    "\n",
    "unique_utm_sources = known_utm_combinations_df['utm_source'].unique()\n",
    "unique_utm_campaigns = known_utm_combinations_df['utm_campaign'].unique()\n",
    "\n",
    "# Make analytics for certain period of time\n",
    "days_ago = 30\n",
    "\n",
    "mock = eval(os.getenv(\"MOCK\", \"False\"))\n",
    "\n",
    "# Timezone\n",
    "timezone = \"Etc/UTC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            pageviews  visitors\n",
      "date                           \n",
      "2023-01-18          0         0\n",
      "2023-01-19          0         0\n",
      "2023-01-20          0         0\n",
      "2023-01-21          0         0\n",
      "2023-01-22          0         0\n",
      "2023-01-23          0         0\n",
      "2023-01-24          0         0\n",
      "2023-01-25          4         3\n",
      "2023-01-26          1         1\n",
      "2023-01-27          0         0\n",
      "2023-01-28          0         0\n",
      "2023-01-29          2         2\n",
      "2023-01-30          0         0\n",
      "2023-01-31          1         1\n",
      "2023-02-01          0         0\n",
      "2023-02-02          0         0\n",
      "2023-02-03          0         0\n",
      "2023-02-04          0         0\n",
      "2023-02-05          1         1\n",
      "2023-02-06          0         0\n",
      "2023-02-07          0         0\n",
      "2023-02-08          0         0\n",
      "2023-02-09          0         0\n",
      "2023-02-10          1         1\n",
      "2023-02-11          0         0\n",
      "2023-02-12          0         0\n",
      "2023-02-13          3         3\n",
      "2023-02-14          0         0\n",
      "2023-02-15          3         3\n",
      "2023-02-16          3         3\n",
      "2023-02-17          3         3\n",
      "----------------------------------------\n",
      "None\n",
      "----------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pytz\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from random import randrange\n",
    "\n",
    "\n",
    "fields_stats_for_simple_analytics = [\n",
    "    \"pageviews\", # the total amount of page views in the specified period\n",
    "    \"visitors\", # the total amount of visitors (unique page views) in the specified period\n",
    "    \"histogram\", # an array with page views and visitors per day\n",
    "    \"countries\", # a list of country codes\n",
    "    \"utm_sources\",\n",
    "    \"utm_campaigns\",\n",
    "    \"referrers\",\n",
    "    \"seconds_on_page\" # the median of seconds a visitor spent on the page\n",
    "]\n",
    "\n",
    "\n",
    "def mock_simple_analytics_stats(stats):\n",
    "    stats = stats.copy()\n",
    "    stats['pageviews'] = 0\n",
    "    stats['visitors'] = 0\n",
    "    \n",
    "    for histogram in stats['histogram']:\n",
    "        page_views = randrange(0, 100)\n",
    "        visitors = page_views // randrange(3, 5)\n",
    "        \n",
    "        histogram['pageviews'] = page_views\n",
    "        histogram['visitors'] = visitors\n",
    "        \n",
    "        # Add to overall stats\n",
    "        stats['pageviews'] += page_views\n",
    "        stats['visitors'] += visitors\n",
    "    \n",
    "    \n",
    "    stats['seconds_on_page'] = randrange(1, 35)\n",
    "    \n",
    "    # It is possible to populate using average amount of visitors, distribute over know utm tags and non-utm visitors\n",
    "    stats['utm_campaigns'] = list(map(lambda value: {\n",
    "        'pageviews': randrange(1, 35),\n",
    "        'seconds_on_page': randrange(1, 30),\n",
    "        'value': value,\n",
    "        'visitors': randrange(10, 50),\n",
    "    }, unique_utm_campaigns))\n",
    "\n",
    "    stats['utm_sources'] = list(map(lambda value: {\n",
    "        'pageviews': randrange(1, 35),\n",
    "        'seconds_on_page': randrange(1, 30),\n",
    "        'value': value,\n",
    "        'visitors': randrange(10, 50),\n",
    "    }, unique_utm_sources))\n",
    "    \n",
    "    return stats\n",
    "    \n",
    "\n",
    "\n",
    "def convert_and_filter_utm_params(stats_utm, known_utm_values):\n",
    "    df = pd.DataFrame(stats_utm)\n",
    "    df = df[df['value'].isin(known_utm_values)]\n",
    "    return df if not df.empty else None\n",
    "\n",
    "\n",
    "def fetch_simple_analytics_stats():\n",
    "    fields_stats_for_simple_analytics_str = ','.join(fields_stats_for_simple_analytics)\n",
    "    url = f\"https://simpleanalytics.com/artbred.io.json?info=false&version=5&fields={fields_stats_for_simple_analytics_str}&timezone={timezone}\"\n",
    "    \n",
    "    current_date = datetime.now(pytz.timezone(timezone)).date()\n",
    "    days_before = current_date - timedelta(days=days_ago)\n",
    "    \n",
    "    url += f\"&start={days_before}&end={current_date}\"\n",
    "\n",
    "    response = requests.get(url, headers={\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    })\n",
    "        \n",
    "    stats = response.json()\n",
    "    if not stats['ok']:\n",
    "        raise ValueError(stats)\n",
    "    \n",
    "    if mock:\n",
    "        stats = mock_simple_analytics_stats(stats)\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "def get_simple_analytics_stats():\n",
    "    stats = fetch_simple_analytics_stats()\n",
    "\n",
    "    if 'countries' in stats:\n",
    "        del stats['countries']\n",
    "\n",
    "    stats['histogram'] = pd.DataFrame(stats['histogram'])\n",
    "    stats['histogram']['date'] = pd.to_datetime(stats['histogram']['date'])\n",
    "    stats['histogram'].set_index('date', inplace=True)\n",
    "\n",
    "    # Delete unknown utm params and convert to pandas data frame\n",
    "    stats['utm_sources'] = convert_and_filter_utm_params(stats['utm_sources'], unique_utm_sources)\n",
    "    stats['utm_campaigns'] = convert_and_filter_utm_params(stats['utm_campaigns'], unique_utm_campaigns)\n",
    "\n",
    "    stats['referrers'] = pd.DataFrame(stats['referrers'])\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "simple_analytics_stats = get_simple_analytics_stats()\n",
    "pprint(simple_analytics_stats['histogram'])\n",
    "print('-' * 40)\n",
    "pprint(simple_analytics_stats['utm_campaigns'])\n",
    "print('-' * 40)\n",
    "pprint(simple_analytics_stats['utm_sources'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 130\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mif\u001b[39;00m mock:\n\u001b[1;32m    128\u001b[0m     fill_redis_with_fake_data()\n\u001b[0;32m--> 130\u001b[0m labels_df, requests_params_endpoints, downloads_df \u001b[39m=\u001b[39m get_data_from_redis()\n\u001b[1;32m    131\u001b[0m \u001b[39m# pprint(labels_df)\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m \u001b[39m*\u001b[39m \u001b[39m40\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 122\u001b[0m, in \u001b[0;36mget_data_from_redis\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mwith\u001b[39;00m create_redis_connection() \u001b[39mas\u001b[39;00m conn:\n\u001b[1;32m    121\u001b[0m     labels_df \u001b[39m=\u001b[39m get_labels_data_from_redis(conn)\n\u001b[0;32m--> 122\u001b[0m     requests_params_endpoints \u001b[39m=\u001b[39m get_requests_params_from_redis(conn)\n\u001b[1;32m    123\u001b[0m     downloads_df \u001b[39m=\u001b[39m get_downloads_data_from_redis(conn)\n\u001b[1;32m    124\u001b[0m     \u001b[39mreturn\u001b[39;00m labels_df, requests_params_endpoints, downloads_df\n",
      "Cell \u001b[0;32mIn[9], line 92\u001b[0m, in \u001b[0;36mget_requests_params_from_redis\u001b[0;34m(conn)\u001b[0m\n\u001b[1;32m     88\u001b[0m     request_params_endpoints[endpoint] \u001b[39m=\u001b[39m params_for_endpoint\n\u001b[1;32m     91\u001b[0m endpoint_column \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(\u001b[39mlist\u001b[39m(request_params_endpoints\u001b[39m.\u001b[39mkeys()), name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mendpoint\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 92\u001b[0m request_params_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([endpoint_column, pd\u001b[39m.\u001b[39;49mDataFrame(request_params_endpoints)], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)  \n\u001b[1;32m     94\u001b[0m request_params_df\u001b[39m.\u001b[39mreplace({\n\u001b[1;32m     95\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mutm_source\u001b[39m\u001b[39m'\u001b[39m: {val: np\u001b[39m.\u001b[39mnan \u001b[39mfor\u001b[39;00m val \u001b[39min\u001b[39;00m \u001b[39mset\u001b[39m(request_params_df[\u001b[39m'\u001b[39m\u001b[39mutm_source\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m-\u001b[39m \u001b[39mset\u001b[39m(unique_utm_sources) \u001b[39m-\u001b[39m {np\u001b[39m.\u001b[39mnan}},\n\u001b[1;32m     96\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mutm_campaign\u001b[39m\u001b[39m'\u001b[39m: {val: np\u001b[39m.\u001b[39mnan \u001b[39mfor\u001b[39;00m val \u001b[39min\u001b[39;00m \u001b[39mset\u001b[39m(request_params_df[\u001b[39m'\u001b[39m\u001b[39mutm_campaign\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m-\u001b[39m \u001b[39mset\u001b[39m(unique_utm_campaigns) \u001b[39m-\u001b[39m {np\u001b[39m.\u001b[39mnan}}\n\u001b[1;32m     97\u001b[0m }, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)  \n\u001b[1;32m     99\u001b[0m request_params_df\u001b[39m.\u001b[39mloc[:, \u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(request_params_df[\u001b[39m'\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m'\u001b[39m], utc\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, unit\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mns\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mdate\n",
      "File \u001b[0;32m~/Documents/Projects/cv/venv/lib/python3.9/site-packages/pandas/core/frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    658\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[1;32m    659\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[1;32m    660\u001b[0m     )\n\u001b[1;32m    662\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    663\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 664\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[1;32m    665\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[1;32m    666\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmrecords\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Projects/cv/venv/lib/python3.9/site-packages/pandas/core/internals/construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    490\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    491\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[0;32m--> 493\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[0;32m~/Documents/Projects/cv/venv/lib/python3.9/site-packages/pandas/core/internals/construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    116\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[1;32m    119\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/Documents/Projects/cv/venv/lib/python3.9/site-packages/pandas/core/internals/construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    664\u001b[0m lengths \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(raw_lengths))\n\u001b[1;32m    665\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(lengths) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 666\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll arrays must be of the same length\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    668\u001b[0m \u001b[39mif\u001b[39;00m have_dicts:\n\u001b[1;32m    669\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    670\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    671\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import json\n",
    "import string\n",
    "import pandas as pd\n",
    "import requests\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('../app')\n",
    "\n",
    "from storage import create_redis_connection, labels_prefix_key, requests_params_set_prefix_key, decode_redis_data, downloads_by_label_id_set_key\n",
    "\n",
    "\n",
    "def api_call(query_position, **kwargs):\n",
    "    params = {k: v for k, v in kwargs.items() if v is not None}\n",
    "    query_url = '&'.join([f\"{k}={v}\" for k, v in params.items()])\n",
    "    response = requests.post(\"http://127.0.0.1:8000/score?\" + query_url, json.dumps({\"position\": query_position}))\n",
    "    if response.status_code == 200:\n",
    "        requests.post(\"http://127.0.0.1:8000/download?\" + query_url, json.dumps({\"token\": response.json()['token']}))\n",
    "\n",
    "\n",
    "def fill_redis_with_fake_data():\n",
    "    # Define probabilities\n",
    "    positions = {\"backend developer\": 0.4, \"product manager\": 0.6}\n",
    "    real_position_probability = 0.7\n",
    "    modify_real_position_probability = 0.85\n",
    "    utm_params_probability = 0.8\n",
    "\n",
    "    for i in range(100):\n",
    "        position, utm_campaign, utm_source = '', None, None\n",
    "\n",
    "        if random.random() < real_position_probability:\n",
    "            position = random.choices(list(positions.keys()), weights=list(positions.values()))[0]\n",
    "\n",
    "            if random.random() < modify_real_position_probability:\n",
    "                num_chars_to_replace = random.randrange(0, len(position) // 4)\n",
    "                indices_to_replace = random.sample(range(len(position)), num_chars_to_replace)\n",
    "                random_string = ''.join(random.choices(string.ascii_letters, k=num_chars_to_replace))\n",
    "                modified_position = \"\".join([random_string[indices_to_replace.index(i)] if i in indices_to_replace else position[i] for i in range(len(position))])\n",
    "                position = modified_position\n",
    "        else:\n",
    "            position = ''.join(random.choices(string.ascii_letters, k=random.randrange(5, 45)))\n",
    "\n",
    "        if random.random() < utm_params_probability:\n",
    "            utm_campaign = random.choice(unique_utm_campaigns)\n",
    "            if random.random() < 0.9:\n",
    "                utm_source = random.choice(unique_utm_sources)\n",
    "\n",
    "        api_call(position, utm_source=utm_source, utm_campaign=utm_campaign)\n",
    "\n",
    "\n",
    "def get_labels_data_from_redis(conn):\n",
    "    labels_list = []\n",
    "\n",
    "    for label_key in conn.keys(labels_prefix_key + \"*\"):\n",
    "        label_byte = conn.hgetall(label_key)\n",
    "        label = decode_redis_data(label_byte)\n",
    "        labels_list.append(label)\n",
    "\n",
    "    return pd.DataFrame(labels_list, columns=[\"id\", \"position\"])\n",
    "\n",
    "\n",
    "def get_requests_params_from_redis(conn):\n",
    "    request_params_endpoints = {}\n",
    "\n",
    "    time_now = time.time()\n",
    "    start_time = time_now - (days_ago * 24 * 60 * 60)\n",
    "\n",
    "    for endpoint_request_key_byte in conn.keys(requests_params_set_prefix_key + \"*\"):\n",
    "        endpoint_request_key = decode_redis_data(endpoint_request_key_byte)\n",
    "        endpoint = endpoint_request_key.replace(requests_params_set_prefix_key, \"\")\n",
    "        \n",
    "        params_for_endpoint_byte = conn.zrangebyscore(endpoint_request_key, start_time, time_now)\n",
    "        params_for_endpoint = decode_redis_data(params_for_endpoint_byte)\n",
    "        params_for_endpoint_df = pd.DataFrame(params_for_endpoint)\n",
    "    \n",
    "        # Replace unknown utm source / utm campaign with NaN\n",
    "        params_for_endpoint_df.replace({\n",
    "            'utm_source': {val: np.nan for val in set(params_for_endpoint_df['utm_source']) - set(unique_utm_sources) - {np.nan}},\n",
    "            'utm_campaign': {val: np.nan for val in set(params_for_endpoint_df['utm_campaign']) - set(unique_utm_campaigns) - {np.nan}}\n",
    "        }, inplace=True)\n",
    "\n",
    "        params_for_endpoint_df['timestamp'] = params_for_endpoint_df['timestamp'].astype(np.int64)\n",
    "        params_for_endpoint_df.loc[:, \"date\"] = pd.to_datetime(params_for_endpoint_df['timestamp'] // 1e9, utc=True, unit='ns').dt.date\n",
    "        params_for_endpoint_df.set_index(\"date\", inplace=True)\n",
    "    \n",
    "        request_params_endpoints[endpoint] = params_for_endpoint\n",
    "\n",
    "    return request_params_endpoints\n",
    "    \n",
    "\n",
    "def get_downloads_data_from_redis(conn):\n",
    "    time_now = int(time.time())\n",
    "    start_time = time_now - (days_ago * 24 * 60 * 60)\n",
    "\n",
    "    downloads_bytes = conn.zrangebyscore(downloads_by_label_id_set_key, start_time, time_now)\n",
    "    downloads_list = decode_redis_data(downloads_bytes)\n",
    "    downloads_df = pd.DataFrame(downloads_list)\n",
    "\n",
    "    downloads_df[\"date\"] = pd.to_datetime(downloads_df[\"timestamp\"] // 1e9, utc=True, unit='ns').dt.date\n",
    "    downloads_df.set_index(\"date\", inplace=True)\n",
    "\n",
    "    return downloads_df\n",
    "\n",
    "\n",
    "def get_data_from_redis():\n",
    "    with create_redis_connection() as conn:\n",
    "        labels_df = get_labels_data_from_redis(conn)\n",
    "        requests_params_endpoints = get_requests_params_from_redis(conn)\n",
    "        downloads_df = get_downloads_data_from_redis(conn)\n",
    "        return labels_df, requests_params_endpoints, downloads_df\n",
    "    \n",
    "    \n",
    "if mock:\n",
    "    fill_redis_with_fake_data()\n",
    "\n",
    "labels_df, requests_params_endpoints, downloads_df = get_data_from_redis()\n",
    "# pprint(labels_df)\n",
    "print('-' * 40)\n",
    "pprint(requests_params_endpoints)\n",
    "print('-' * 40)\n",
    "# print(downloads_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_name = 'analytics_mock' if mock else 'analytics'\n",
    "\n",
    "with open(f'../data/analytics/{file_name}.pickle', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        \"simple_analytics\": simple_analytics_stats,\n",
    "        \"labels\": labels_df,\n",
    "        \"requests_params_endpoints\": requests_params_endpoints,\n",
    "        \"downloads\": downloads_df\n",
    "    }, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "c33d8f67f562cce5859f9a540b527199a02a3e594481b522e300f255251b4913"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
